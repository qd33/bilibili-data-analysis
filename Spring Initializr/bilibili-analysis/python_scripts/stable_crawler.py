# stable_crawler.py
import asyncio
import requests
from bilibili_api import video
import pymysql
from datetime import datetime

class StableBilibiliCrawler:
    def __init__(self):
        self.db_config = {
            'host': 'localhost',
            'user': 'root',
            'password': '123456789',
            'database': 'bilibili_db',
            'charset': 'utf8mb4'
        }

    def get_connection(self):
        return pymysql.connect(**self.db_config)

    async def crawl_with_api(self, bv_id):
        """ä½¿ç”¨bilibili-api-pythonåº“çˆ¬å–æ•°æ®:cite[3]"""
        try:
            # å®ä¾‹åŒ–Videoç±»
            v = video.Video(bvid=bv_id)
            # è·å–ä¿¡æ¯
            info = await v.get_info()
            return info
        except Exception as e:
            print(f"APIçˆ¬å–å¤±è´¥ {bv_id}: {e}")
            return None

    def insert_up(self, up_data):
        """æ’å…¥UPä¸»æ•°æ®"""
        connection = self.get_connection()
        try:
            with connection.cursor() as cursor:
                sql = """
                INSERT IGNORE INTO up (uid, name, avatar) 
                VALUES (%s, %s, %s)
                """
                cursor.execute(sql, (
                    up_data['uid'],
                    up_data['name'],
                    up_data['avatar']
                ))
                connection.commit()
                return cursor.lastrowid
        finally:
            connection.close()

    def insert_video(self, video_data, up_id):
        """æ’å…¥è§†é¢‘æ•°æ®"""
        connection = self.get_connection()
        try:
            with connection.cursor() as cursor:
                sql = """
                INSERT IGNORE INTO video 
                (bv_id, title, cover_url, description, publish_time, video_partition, up_id) 
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                """
                cursor.execute(sql, (
                    video_data['bv_id'],
                    video_data['title'],
                    video_data['cover_url'],
                    video_data['description'],
                    video_data['publish_time'],
                    video_data['partition'],
                    up_id
                ))
                connection.commit()
                return cursor.lastrowid
        finally:
            connection.close()

    def insert_video_stat(self, video_id, stats):
        """æ’å…¥è§†é¢‘ç»Ÿè®¡æ•°æ®"""
        connection = self.get_connection()
        try:
            with connection.cursor() as cursor:
                sql = """
                INSERT IGNORE INTO video_stat 
                (video_id, record_date, view_count, like_count, coin_count, favorite_count, 
                 danmaku_count, reply_count, share_count) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                cursor.execute(sql, (
                    video_id,
                    datetime.now().date(),
                    stats.get('view', 0),
                    stats.get('like', 0),
                    stats.get('coin', 0),
                    stats.get('favorite', 0),
                    stats.get('danmaku', 0),
                    stats.get('reply', 0),
                    stats.get('share', 0)
                ))
                connection.commit()
        finally:
            connection.close()

    async def process_video(self, bv_id):
        """å¤„ç†å•ä¸ªè§†é¢‘"""
        print(f"\nğŸ¬ å¤„ç†è§†é¢‘: {bv_id}")

        # ä½¿ç”¨APIçˆ¬å–æ•°æ®
        info = await self.crawl_with_api(bv_id)
        if not info:
            return False

        print(f"âœ… çˆ¬å–æˆåŠŸ: {info['title']}")

        # æå–UPä¸»æ•°æ®
        up_data = {
            'uid': str(info['owner']['mid']),
            'name': info['owner']['name'],
            'avatar': info['owner']['face']
        }

        # æ’å…¥UPä¸»
        up_id = self.insert_up(up_data)
        print(f"âœ… UPä¸»æ’å…¥å®Œæˆ: {up_data['name']}")

        # å‡†å¤‡è§†é¢‘æ•°æ®
        video_data = {
            'bv_id': info['bvid'],
            'title': info['title'],
            'cover_url': info['pic'],
            'description': info['desc'][:500] if info['desc'] else "",
            'publish_time': datetime.fromtimestamp(info['pubdate']),
            'partition': self.get_partition_name(info['tid'])
        }

        # æ’å…¥è§†é¢‘
        video_id = self.insert_video(video_data, up_id)
        if video_id:
            print(f"âœ… è§†é¢‘æ’å…¥æˆåŠŸ: {video_data['title']}")

            # æ’å…¥ç»Ÿè®¡æ•°æ®
            stats = {
                'view': info['stat']['view'],
                'like': info['stat']['like'],
                'coin': info['stat']['coin'],
                'favorite': info['stat']['favorite'],
                'danmaku': info['stat']['danmaku'],
                'reply': info['stat']['reply'],
                'share': info['stat']['share']
            }
            self.insert_video_stat(video_id, stats)
            print(f"ğŸ“Š ç»Ÿè®¡æ•°æ®æ’å…¥æˆåŠŸ")
            return True
        else:
            print(f"âš ï¸ è§†é¢‘å¯èƒ½å·²å­˜åœ¨")
            return False

    def get_partition_name(self, tid):
        """è·å–åˆ†åŒºåç§°:cite[3]"""
        partitions = {
            1: "åŠ¨ç”»", 17: "å•æœºæ¸¸æˆ", 3: "éŸ³ä¹",
            129: "èˆè¹ˆ", 4: "æ¸¸æˆ", 36: "çŸ¥è¯†",
            188: "ç§‘æŠ€", 160: "ç”Ÿæ´»", 119: "é¬¼ç•œ",
            155: "æ—¶å°š", 165: "å¹¿å‘Š", 5: "å¨±ä¹"
        }
        return partitions.get(tid, "å…¶ä»–")

    def check_database(self):
        """æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"""
        connection = self.get_connection()
        try:
            with connection.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) FROM video")
                video_count = cursor.fetchone()[0]
                cursor.execute("SELECT COUNT(*) FROM up")
                up_count = cursor.fetchone()[0]
                print(f"\nğŸ“Š å½“å‰æ•°æ®åº“çŠ¶æ€: {video_count} ä¸ªè§†é¢‘, {up_count} ä¸ªUPä¸»")
        finally:
            connection.close()

async def main():
    crawler = StableBilibiliCrawler()

    # æ£€æŸ¥å½“å‰çŠ¶æ€
    crawler.check_database()

    # å¤„ç†è§†é¢‘åˆ—è¡¨
    bv_ids = [
        "BV1LiHWzaEzy",  # ä¹‹å‰æˆåŠŸçš„
        "BV1u3xTzJEku",  # ä¹‹å‰æˆåŠŸçš„
        "BV1xx411c79H",  # å¤‡ç”¨çš„
    ]

    success_count = 0
    for bv_id in bv_ids:
        if await crawler.process_video(bv_id):
            success_count += 1

    # æœ€ç»ˆçŠ¶æ€
    print(f"\nğŸ‰ å®Œæˆ! æˆåŠŸå¤„ç† {success_count} ä¸ªè§†é¢‘")
    crawler.check_database()

if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())